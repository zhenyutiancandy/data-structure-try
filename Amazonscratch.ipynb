{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d23ae57-0526-4e8b-be3b-04b6e97e50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--keyword KEYWORD] [--products PRODUCTS] [--reviews REVIEWS] [--market MARKET]\n",
      "                             [--user-agent USER_AGENT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Candy\\AppData\\Roaming\\jupyter\\runtime\\kernel-102e49d4-923a-4296-a2a0-10944b156a6a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Candy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Free MVP: DuckDuckGo 搜索 Amazon 链接 -> 采集商品信息 + 热门好评 -> 生成视频文稿（本地“AI风格”摘要）\n",
    "仅用免费工具：requests + BeautifulSoup + 规则化摘要，不调用付费 API。\n",
    "\n",
    "用法：\n",
    "    python main.py --keyword \"wireless earbuds\" --products 2 --reviews 3 --market \"com\"\n",
    "输出：\n",
    "    ./output/results.json, ./output/results.csv, ./output/script_<ASIN>.md\n",
    "'''\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "import urllib.parse as up\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    pd = None\n",
    "\n",
    "DEFAULT_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}\n",
    "\n",
    "DDG_HTML = \"https://html.duckduckgo.com/html/\"\n",
    "TIMEOUT = 20\n",
    "\n",
    "def sleep_jitter(a=1.0, b=2.0):\n",
    "    time.sleep(random.uniform(a, b))\n",
    "\n",
    "def ddg_search_amazon_links(keyword: str, market: str = \"com\", max_links: int = 5, headers: Optional[dict]=None) -> List[str]:\n",
    "    '''\n",
    "    使用 DuckDuckGo HTML 搜索，返回包含 /dp/ 或 /gp/product/ 的 Amazon 商品链接。\n",
    "    '''\n",
    "    if headers is None:\n",
    "        headers = DEFAULT_HEADERS\n",
    "    q = f\"site:amazon.{market} {keyword}\"\n",
    "    data = {\"q\": q}\n",
    "    resp = requests.post(DDG_HTML, data=data, headers=headers, timeout=TIMEOUT)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "    links = []\n",
    "    for a in soup.select(\"a.result__a\"):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        real = up.unquote(href)\n",
    "        if \"http\" in real:\n",
    "            real_url = real\n",
    "        else:\n",
    "            real_url = a.get(\"href\", \"\")\n",
    "        if (\"amazon.\" in real_url) and (\"/dp/\" in real_url or \"/gp/product/\" in real_url):\n",
    "            clean = real_url.split(\"/ref=\")[0].split(\"?\")[0]\n",
    "            if clean not in links:\n",
    "                links.append(clean)\n",
    "        if len(links) >= max_links:\n",
    "            break\n",
    "    return links\n",
    "\n",
    "def extract_asin(url: str) -> Optional[str]:\n",
    "    m = re.search(r\"/dp/([A-Z0-9]{10})\", url)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    m = re.search(r\"/gp/product/([A-Z0-9]{10})\", url)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "def get(url: str, headers: Optional[dict]=None) -> requests.Response:\n",
    "    if headers is None:\n",
    "        headers = DEFAULT_HEADERS\n",
    "    resp = requests.get(url, headers=headers, timeout=TIMEOUT)\n",
    "    resp.raise_for_status()\n",
    "    return resp\n",
    "\n",
    "def parse_product_page(html_text: str) -> Dict[str, Any]:\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    title = soup.select_one(\"#productTitle\")\n",
    "    title = title.get_text(strip=True) if title else \"\"\n",
    "\n",
    "    bullets = [li.get_text(\" \", strip=True) for li in soup.select(\"#feature-bullets ul li:not(.aok-hidden)\")]\n",
    "    bullets = [b for b in bullets if b and \"Click to play\" not in b]\n",
    "\n",
    "    price_el = soup.select_one(\"#corePrice_feature_div .a-offscreen\") or soup.select_one(\".a-price .a-offscreen\")\n",
    "    price = price_el.get_text(strip=True) if price_el else \"\"\n",
    "\n",
    "    rating_el = soup.select_one(\"span[data-hook='rating-out-of-text']\") or soup.select_one(\".a-icon-alt\")\n",
    "    rating = rating_el.get_text(strip=True) if rating_el else \"\"\n",
    "\n",
    "    review_count_el = soup.select_one(\"#acrCustomerReviewText\") or soup.select_one(\"span[data-hook='total-review-count']\")\n",
    "    review_count = review_count_el.get_text(strip=True) if review_count_el else \"\"\n",
    "\n",
    "    brand = \"\"\n",
    "    for th in soup.select(\"#productDetails_techSpec_section_1 th, #prodDetails tr th\"):\n",
    "        if th.get_text(strip=True).lower() in [\"brand\", \"品牌\"]:\n",
    "            td = th.find_next(\"td\")\n",
    "            brand = td.get_text(\" \", strip=True) if td else \"\"\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"bullets\": bullets,\n",
    "        \"price\": price,\n",
    "        \"rating\": rating,\n",
    "        \"review_count\": review_count,\n",
    "        \"brand\": brand,\n",
    "    }\n",
    "\n",
    "def parse_reviews_page(html_text: str, max_reviews: int = 3) -> List[Dict[str, Any]]:\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    reviews = []\n",
    "    for card in soup.select(\"div[data-hook='review']\"):\n",
    "        if len(reviews) >= max_reviews:\n",
    "            break\n",
    "        stars_el = card.select_one(\"i[data-hook='review-star-rating'] span\") or card.select_one(\"i.a-icon-star span\")\n",
    "        stars = stars_el.get_text(strip=True) if stars_el else \"\"\n",
    "        title_el = card.select_one(\"a[data-hook='review-title'] span\")\n",
    "        title = title_el.get_text(\" \", strip=True) if title_el else \"\"\n",
    "        body_el = card.select_one(\"span[data-hook='review-body'] span\")\n",
    "        body = body_el.get_text(\" \", strip=True) if body_el else \"\"\n",
    "        helpful_el = card.select_one(\"span.cr-vote span\")\n",
    "        helpful = helpful_el.get_text(\" \", strip=True) if helpful_el else \"\"\n",
    "        reviews.append({\n",
    "            \"stars\": stars,\n",
    "            \"title\": title,\n",
    "            \"body\": body,\n",
    "            \"helpful\": helpful,\n",
    "        })\n",
    "    return reviews\n",
    "\n",
    "def build_reviews_url(asin: str, market: str=\"com\") -> str:\n",
    "    return f\"https://www.amazon.{market}/product-reviews/{asin}/?sortBy=helpful\"\n",
    "\n",
    "def simple_keywords(text: str, topk: int = 8) -> List[str]:\n",
    "    stop = set(\"a an the and or for with from have has this that your you our are is was were to of in on at by it as be can will just very more most not only also get got make makes made into over about after before under above between com amazon use using used product\".split())\n",
    "    words = re.findall(r\"[A-Za-z][A-Za-z0-9\\-\\+]{2,}\", text.lower())\n",
    "    freq = {}\n",
    "    for w in words:\n",
    "        if w in stop:\n",
    "            continue\n",
    "        freq[w] = freq.get(w, 0) + 1\n",
    "    return [w for w,_ in sorted(freq.items(), key=lambda x: (-x[1], x[0]))[:topk]]\n",
    "\n",
    "def pick_selling_points(bullets: List[str], fallback_text: str, k: int = 3) -> List[str]:\n",
    "    points = [b for b in bullets if len(b) > 0][:k]\n",
    "    if len(points) < k:\n",
    "        kws = simple_keywords(fallback_text, topk=10)\n",
    "        while len(points) < k and kws:\n",
    "            points.append(f\"Key feature: {kws.pop(0)}\")\n",
    "    return points[:k]\n",
    "\n",
    "def make_video_script(prod: Dict[str, Any], reviews: List[Dict[str, Any]]) -> str:\n",
    "    title = prod.get(\"title\",\"\").strip()\n",
    "    bullets = prod.get(\"bullets\", [])\n",
    "    rating = prod.get(\"rating\", \"\")\n",
    "    review_count = prod.get(\"review_count\", \"\")\n",
    "    price = prod.get(\"price\", \"\")\n",
    "    brand = prod.get(\"brand\", \"\")\n",
    "\n",
    "    fallback = \" \".join([title] + bullets)\n",
    "    selling_points = pick_selling_points(bullets, fallback_text=fallback, k=3)\n",
    "\n",
    "    top_quotes = []\n",
    "    for r in reviews[:3]:\n",
    "        body = r.get(\"body\",\"\").strip()\n",
    "        if body:\n",
    "            body = re.sub(r\"\\s+\", \" \", body)\n",
    "            if len(body) > 180:\n",
    "                body = body[:180].rstrip() + \"...\"\n",
    "            top_quotes.append(f\"“{body}”\")\n",
    "\n",
    "    hook = f\"还在为挑选 {brand + ' ' if brand else ''}{title[:50]} 犹豫吗？看看这款的真实口碑！\"\n",
    "    social = \"\\n\".join([f\"- {q}\" for q in top_quotes]) if top_quotes else \"- 来自用户的真实好评，口碑在线。\"\n",
    "\n",
    "    script = f'''# 视频脚本（草案）\n",
    "\n",
    "**Hook（抓注意力）**  \n",
    "{hook}\n",
    "\n",
    "**产品亮点**  \n",
    "- {selling_points[0] if len(selling_points)>0 else ''}\n",
    "- {selling_points[1] if len(selling_points)>1 else ''}\n",
    "- {selling_points[2] if len(selling_points)>2 else ''}\n",
    "\n",
    "**社会证明（好评节选）**  \n",
    "{social}\n",
    "\n",
    "**数据背书**  \n",
    "- 评分：{rating or 'N/A'}，评论数：{review_count or 'N/A'}  \n",
    "- 价格参考：{price or 'N/A'} （以页面为准）\n",
    "\n",
    "**结尾 CTA**  \n",
    "如果你也在找一款靠谱的 {brand or ''}{title[:20]}，不妨点开看看，早点入手！\n",
    "'''\n",
    "    return script\n",
    "\n",
    "def scrape_one_product(url: str, market: str, headers: dict, review_n: int) -> Dict[str, Any]:\n",
    "    asin = extract_asin(url)\n",
    "    if not asin:\n",
    "        raise ValueError(f\"无法从链接中提取 ASIN：{url}\")\n",
    "    prod_url = f\"https://www.amazon.{market}/dp/{asin}\"\n",
    "    resp = get(prod_url, headers=headers)\n",
    "    prod = parse_product_page(resp.text)\n",
    "\n",
    "    time.sleep(random.uniform(1.0, 2.0))\n",
    "    rurl = build_reviews_url(asin, market=market)\n",
    "    rresp = get(rurl, headers=headers)\n",
    "    revs = parse_reviews_page(rresp.text, max_reviews=review_n)\n",
    "\n",
    "    prod[\"asin\"] = asin\n",
    "    prod[\"url\"] = prod_url\n",
    "    prod[\"reviews\"] = revs\n",
    "    prod[\"video_script\"] = make_video_script(prod, revs)\n",
    "    return prod\n",
    "\n",
    "def save_outputs(items: List[Dict[str, Any]], outdir: str):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    with open(os.path.join(outdir, \"results.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(items, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        rows.append({\n",
    "            \"asin\": it.get(\"asin\",\"\"),\n",
    "            \"title\": it.get(\"title\",\"\"),\n",
    "            \"price\": it.get(\"price\",\"\"),\n",
    "            \"rating\": it.get(\"rating\",\"\"),\n",
    "            \"review_count\": it.get(\"review_count\",\"\"),\n",
    "            \"url\": it.get(\"url\",\"\"),\n",
    "        })\n",
    "    with open(os.path.join(outdir, \"results.csv\"), \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()) if rows else [\"asin\",\"title\",\"price\",\"rating\",\"review_count\",\"url\"])\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    for it in items:\n",
    "        asin = it.get(\"asin\",\"NA\")\n",
    "        script = it.get(\"video_script\",\"\")\n",
    "        with open(os.path.join(outdir, f\"script_{asin}.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(script)\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--keyword\", type=str, default=\"best seller gadgets\", help=\"DuckDuckGo 搜索关键词\")\n",
    "    ap.add_argument(\"--products\", type=int, default=2, help=\"抓取商品数量\")\n",
    "    ap.add_argument(\"--reviews\", type=int, default=3, help=\"每个商品抓取评论条数\")\n",
    "    ap.add_argument(\"--market\", type=str, default=\"com\", help=\"Amazon 站点，如 com / co.uk / de / jp\")\n",
    "    ap.add_argument(\"--user-agent\", type=str, default=\"\", help=\"自定义 UA\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    headers = DEFAULT_HEADERS.copy()\n",
    "    if args.user_agent:\n",
    "        headers[\"User-Agent\"] = args.user_agent\n",
    "\n",
    "    outdir = os.path.join(os.path.dirname(__file__), \"output\")\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    print(f\"[1/3] 搜索 Amazon 链接：{args.keyword}\")\n",
    "    links = ddg_search_amazon_links(args.keyword, market=args.market, max_links=args.products*3, headers=headers)\n",
    "    print(f\"搜索到候选链接 {len(links)} 条\")\n",
    "\n",
    "    seen_asin = set()\n",
    "    picked = []\n",
    "    for link in links:\n",
    "        asin = extract_asin(link)\n",
    "        if asin and asin not in seen_asin:\n",
    "            seen_asin.add(asin)\n",
    "            picked.append(link)\n",
    "        if len(picked) >= args.products:\n",
    "            break\n",
    "\n",
    "    items = []\n",
    "    for idx, url in enumerate(picked, 1):\n",
    "        try:\n",
    "            print(f\"[2/3] 抓取第 {idx}/{len(picked)} 个商品：{url}\")\n",
    "            item = scrape_one_product(url, market=args.market, headers=headers, review_n=args.reviews)\n",
    "            items.append(item)\n",
    "            time.sleep(random.uniform(1.0, 2.0))\n",
    "        except Exception as e:\n",
    "            print(f\"!! 抓取失败：{e}\")\n",
    "\n",
    "    print(f\"[3/3] 保存输出到 {outdir}\")\n",
    "    save_outputs(items, outdir)\n",
    "\n",
    "    if pd is not None and items:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame([{\n",
    "                \"asin\": it.get(\"asin\",\"\"),\n",
    "                \"title\": it.get(\"title\",\"\"),\n",
    "                \"price\": it.get(\"price\",\"\"),\n",
    "                \"rating\": it.get(\"rating\",\"\"),\n",
    "                \"review_count\": it.get(\"review_count\",\"\"),\n",
    "                \"url\": it.get(\"url\",\"\"),\n",
    "            } for it in items])\n",
    "            xlsx_path = os.path.join(outdir, \"results.xlsx\")\n",
    "            df.to_excel(xlsx_path, index=False)\n",
    "            print(f\"已保存：{xlsx_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存 XLSX 失败：{e}\")\n",
    "\n",
    "    print(\"完成。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c967b1-b7fb-4e26-9a89-11fa8064ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
